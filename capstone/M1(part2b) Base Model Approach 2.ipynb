{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M1(part2b) - Base Model Approach 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71q95jI8EiG"
      },
      "source": [
        "**Approach 2 - Long-Short Term Memory (LSTM's)**<br>\r\n",
        "**RUN THIS CELL IF RUNNING IN GOOGLE COLAB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkk7yJOi7W4v",
        "outputId": "214d2f82-deaa-4311-d5d6-a0359b4c4076"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/capstone')\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2seG6Pb8dhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2112a4-1408-4116-aa6d-0b40fe00ef3d"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\r\n",
        "from ProjectModules.PlottingModule import distribution_plot\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installing wordcloud python package...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFWAGONSfSd4"
      },
      "source": [
        "**Loading upsampled data from part2a:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "jf_92zCc8s6M",
        "outputId": "6b28a7d5-bd50-4fce-cffc-862bf219422f"
      },
      "source": [
        "# RUN THIS DATAPATH IF RUNNING IN GOOGLE COLAB, GIVE THE CORRECT PATH TO THE DATA\r\n",
        "DATAPATH = '/content/drive/MyDrive/capstone/DataFiles/'\r\n",
        "# *************************** --------------------------************************************\r\n",
        "# DATAPATH = 'DataFiles/'\r\n",
        "\r\n",
        "data = pd.read_csv(DATAPATH+\"upsampled_processed_data.csv\")\r\n",
        "df = data.copy() #making copy of the data\r\n",
        "print(df.shape)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8040, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>combined_tokens</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>login issue verify user detail employee manage...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>outlook team meeting skype meeting etc appear ...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>cant log vpn cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page unable access hr to...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ... Assignment group\n",
              "0                 login issue  ...            GRP_0\n",
              "1                     outlook  ...            GRP_0\n",
              "2                cant log vpn  ...            GRP_0\n",
              "3  unable access hr tool page  ...            GRP_0\n",
              "4                 skype error  ...            GRP_0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clPWyuUdfadU"
      },
      "source": [
        "**we will drop the combined_tokens column and will create a new combined_tokens column again in a slightly different way. Earlier we simply merged the short description and description column since we had to make bow and tfidf matrix but now since we will be making using of \"sequences\" we cant have repetitive sequences one after another. We have a lot of records where short description and description are exactly same... hence if they are exactly same we dont want to club them and unnecessarily increase the length of our sequences therefore we will club them in a better way later on:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGtQUo0qLScK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e9a0ef59-f2c8-4f51-9997-ea903d4eab17"
      },
      "source": [
        "df.drop(\"combined_tokens\", inplace=True, axis=1)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ... Assignment group\n",
              "0                 login issue  ...            GRP_0\n",
              "1                     outlook  ...            GRP_0\n",
              "2                cant log vpn  ...            GRP_0\n",
              "3  unable access hr tool page  ...            GRP_0\n",
              "4                 skype error  ...            GRP_0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38VpElVB_HU"
      },
      "source": [
        "**As we explained in part2a before, we removed only those records that had missing values in both description and short description columns. If either of the two had text, we retained it<br>\r\n",
        "The missing text was saved with an empty string in the dataframe during pre-processing, but when we converted it to csv and loaded it again, the empty strings display with NaN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fSvbSQA84zT",
        "outputId": "7cd974ec-b5c3-48fd-c23a-2c6e94b165e1"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cleaned_short_desc    16\n",
              "cleaned_desc          52\n",
              "Assignment group       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-A-VK8LCWta"
      },
      "source": [
        "Otherwise if you'll see there is no record where both description and short description are missing: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "kusxMCz187-P",
        "outputId": "183ede42-d571-47db-830d-b7e6e5920e7d"
      },
      "source": [
        "df[(df['cleaned_short_desc'].isnull()) & (df['cleaned_desc'].isnull())]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [cleaned_short_desc, cleaned_desc, Assignment group]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMdOGWNCen-"
      },
      "source": [
        "So lets fill NaNs with empty string again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo3IWS-C8-ab"
      },
      "source": [
        "df['cleaned_short_desc'].fillna(value=\"\",inplace=True)\r\n",
        "df['cleaned_desc'].fillna(value = \"\",inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAprR18oCcQQ"
      },
      "source": [
        "**Making vocabulary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BHtnOm_ClQo",
        "outputId": "6dc88bcb-a6c3-4fa8-85dd-d638c1195e8e"
      },
      "source": [
        "vocabulary = set()\r\n",
        "\r\n",
        "for txt in df[\"cleaned_desc\"]:\r\n",
        "    unq_words = set(txt.split())\r\n",
        "    vocabulary.update(unq_words)\r\n",
        "\r\n",
        "for txt in df[\"cleaned_short_desc\"]:\r\n",
        "    unq_words = set(txt.split())\r\n",
        "    vocabulary.update(unq_words)\r\n",
        "\r\n",
        "# appending 'DUMMYWORD' which will be helpful in padding\r\n",
        "vocabulary = list(vocabulary)\r\n",
        "vocabulary.append(\"DUMMYWORD\")\r\n",
        "\r\n",
        "print(\"Total unique words in the vocabulary from both description and short description:\",len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the vocabulary from both description and short description: 19235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBzmDa-MggC0"
      },
      "source": [
        "**Converting vocabulary to numerical values:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYIMfEPClfk"
      },
      "source": [
        "# mapping vocabulary to numbers\r\n",
        "vocab2id = {w: i for i, w in enumerate(vocabulary)}\r\n",
        "\r\n",
        "# mapping numbers to vocabulary\r\n",
        "id2vocab = {v: k for k, v in vocab2id.items()}\r\n",
        "\r\n",
        "# transforming dataset to numerical tokens\r\n",
        "def convert_words_to_numbers(txt):\r\n",
        "  return [vocab2id[i] for i in txt.split()]\r\n",
        "\r\n",
        "# transforming\r\n",
        "df[\"desc_transformed\"] = df[\"cleaned_desc\"].apply(convert_words_to_numbers)\r\n",
        "df[\"shortdesc_transformed\"] = df[\"cleaned_short_desc\"].apply(convert_words_to_numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_UD3QvSgsCb"
      },
      "source": [
        "**desc_transformed and shortdesc_transformed are the numerical versions of cleaned_short_desc and cleaned_desc columns**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "kSQiOsMVCliC",
        "outputId": "117b0ef0-7ede-4534-e66b-a9e8a591f35f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>desc_transformed</th>\n",
              "      <th>shortdesc_transformed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[2731, 5291, 17809, 8878, 18872, 10006, 12410,...</td>\n",
              "      <td>[6990, 7762]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[16497, 14688, 10355, 14688, 16855, 4214, 1855...</td>\n",
              "      <td>[1855]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[18166, 4073, 10410, 411]</td>\n",
              "      <td>[16726, 4073, 10410]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ...            shortdesc_transformed\n",
              "0                 login issue  ...                     [6990, 7762]\n",
              "1                     outlook  ...                           [1855]\n",
              "2                cant log vpn  ...             [16726, 4073, 10410]\n",
              "3  unable access hr tool page  ...  [3080, 5695, 1934, 14842, 2417]\n",
              "4                 skype error  ...                   [10355, 12242]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "432II2aug3vl"
      },
      "source": [
        "**Combining tokens - like we said we have descriptions and short descriptions that are exactly same. Hence below is a function that returns only description tokens if both are exactly same and if not... it returns description and short description tokens after clubbing them together**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Q3lcrhIuda"
      },
      "source": [
        "def clubbing_columns(row):\r\n",
        "  if(row[\"shortdesc_transformed\"] == row[\"desc_transformed\"]):\r\n",
        "    return row[\"desc_transformed\"]\r\n",
        "  else:\r\n",
        "    return row[\"shortdesc_transformed\"] + row[\"desc_transformed\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLCFJbYyIYaI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5efe7328-e950-42d2-8346-973a32894ad4"
      },
      "source": [
        "df[\"combined_tokens\"] = df[[\"shortdesc_transformed\",\"desc_transformed\"]].apply(clubbing_columns, axis=1)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>desc_transformed</th>\n",
              "      <th>shortdesc_transformed</th>\n",
              "      <th>combined_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[2731, 5291, 17809, 8878, 18872, 10006, 12410,...</td>\n",
              "      <td>[6990, 7762]</td>\n",
              "      <td>[6990, 7762, 2731, 5291, 17809, 8878, 18872, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[16497, 14688, 10355, 14688, 16855, 4214, 1855...</td>\n",
              "      <td>[1855]</td>\n",
              "      <td>[1855, 16497, 14688, 10355, 14688, 16855, 4214...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[18166, 4073, 10410, 411]</td>\n",
              "      <td>[16726, 4073, 10410]</td>\n",
              "      <td>[16726, 4073, 10410, 18166, 4073, 10410, 411]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ...                                    combined_tokens\n",
              "0                 login issue  ...  [6990, 7762, 2731, 5291, 17809, 8878, 18872, 1...\n",
              "1                     outlook  ...  [1855, 16497, 14688, 10355, 14688, 16855, 4214...\n",
              "2                cant log vpn  ...      [16726, 4073, 10410, 18166, 4073, 10410, 411]\n",
              "3  unable access hr tool page  ...                    [3080, 5695, 1934, 14842, 2417]\n",
              "4                 skype error  ...                                     [10355, 12242]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q27n5OTMh2kT"
      },
      "source": [
        "**Checking for Null values again:**<br>No missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YX7mn1NLKc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120c102d-cf01-4c90-9b6f-6eb0bef3fa8f"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cleaned_short_desc       0\n",
              "cleaned_desc             0\n",
              "Assignment group         0\n",
              "desc_transformed         0\n",
              "shortdesc_transformed    0\n",
              "combined_tokens          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY6wa98Zh_QD"
      },
      "source": [
        "**Lets transform the target variable. We have 74 unique labels in the target class. We will transform the target variable in the one-hot binarizer form:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pjwZ1pJNKlJZ",
        "outputId": "e889a784-0e1d-4810-dd87-32617c5e7c22"
      },
      "source": [
        "df=pd.get_dummies(df, columns=['Assignment group'])\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>desc_transformed</th>\n",
              "      <th>shortdesc_transformed</th>\n",
              "      <th>combined_tokens</th>\n",
              "      <th>Assignment group_GRP_0</th>\n",
              "      <th>Assignment group_GRP_1</th>\n",
              "      <th>Assignment group_GRP_10</th>\n",
              "      <th>Assignment group_GRP_11</th>\n",
              "      <th>Assignment group_GRP_12</th>\n",
              "      <th>Assignment group_GRP_13</th>\n",
              "      <th>Assignment group_GRP_14</th>\n",
              "      <th>Assignment group_GRP_15</th>\n",
              "      <th>Assignment group_GRP_16</th>\n",
              "      <th>Assignment group_GRP_17</th>\n",
              "      <th>Assignment group_GRP_18</th>\n",
              "      <th>Assignment group_GRP_19</th>\n",
              "      <th>Assignment group_GRP_2</th>\n",
              "      <th>Assignment group_GRP_20</th>\n",
              "      <th>Assignment group_GRP_21</th>\n",
              "      <th>Assignment group_GRP_22</th>\n",
              "      <th>Assignment group_GRP_23</th>\n",
              "      <th>Assignment group_GRP_24</th>\n",
              "      <th>Assignment group_GRP_25</th>\n",
              "      <th>Assignment group_GRP_26</th>\n",
              "      <th>Assignment group_GRP_27</th>\n",
              "      <th>Assignment group_GRP_28</th>\n",
              "      <th>Assignment group_GRP_29</th>\n",
              "      <th>Assignment group_GRP_3</th>\n",
              "      <th>Assignment group_GRP_30</th>\n",
              "      <th>Assignment group_GRP_31</th>\n",
              "      <th>Assignment group_GRP_32</th>\n",
              "      <th>Assignment group_GRP_33</th>\n",
              "      <th>Assignment group_GRP_34</th>\n",
              "      <th>Assignment group_GRP_35</th>\n",
              "      <th>Assignment group_GRP_36</th>\n",
              "      <th>Assignment group_GRP_37</th>\n",
              "      <th>Assignment group_GRP_38</th>\n",
              "      <th>Assignment group_GRP_39</th>\n",
              "      <th>Assignment group_GRP_4</th>\n",
              "      <th>Assignment group_GRP_40</th>\n",
              "      <th>Assignment group_GRP_41</th>\n",
              "      <th>Assignment group_GRP_42</th>\n",
              "      <th>Assignment group_GRP_43</th>\n",
              "      <th>Assignment group_GRP_44</th>\n",
              "      <th>Assignment group_GRP_45</th>\n",
              "      <th>Assignment group_GRP_46</th>\n",
              "      <th>Assignment group_GRP_47</th>\n",
              "      <th>Assignment group_GRP_48</th>\n",
              "      <th>Assignment group_GRP_49</th>\n",
              "      <th>Assignment group_GRP_5</th>\n",
              "      <th>Assignment group_GRP_50</th>\n",
              "      <th>Assignment group_GRP_51</th>\n",
              "      <th>Assignment group_GRP_52</th>\n",
              "      <th>Assignment group_GRP_53</th>\n",
              "      <th>Assignment group_GRP_54</th>\n",
              "      <th>Assignment group_GRP_55</th>\n",
              "      <th>Assignment group_GRP_56</th>\n",
              "      <th>Assignment group_GRP_57</th>\n",
              "      <th>Assignment group_GRP_58</th>\n",
              "      <th>Assignment group_GRP_59</th>\n",
              "      <th>Assignment group_GRP_6</th>\n",
              "      <th>Assignment group_GRP_60</th>\n",
              "      <th>Assignment group_GRP_61</th>\n",
              "      <th>Assignment group_GRP_62</th>\n",
              "      <th>Assignment group_GRP_63</th>\n",
              "      <th>Assignment group_GRP_64</th>\n",
              "      <th>Assignment group_GRP_65</th>\n",
              "      <th>Assignment group_GRP_66</th>\n",
              "      <th>Assignment group_GRP_67</th>\n",
              "      <th>Assignment group_GRP_68</th>\n",
              "      <th>Assignment group_GRP_69</th>\n",
              "      <th>Assignment group_GRP_7</th>\n",
              "      <th>Assignment group_GRP_70</th>\n",
              "      <th>Assignment group_GRP_71</th>\n",
              "      <th>Assignment group_GRP_72</th>\n",
              "      <th>Assignment group_GRP_73</th>\n",
              "      <th>Assignment group_GRP_8</th>\n",
              "      <th>Assignment group_GRP_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>[2731, 5291, 17809, 8878, 18872, 10006, 12410,...</td>\n",
              "      <td>[6990, 7762]</td>\n",
              "      <td>[6990, 7762, 2731, 5291, 17809, 8878, 18872, 1...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>[16497, 14688, 10355, 14688, 16855, 4214, 1855...</td>\n",
              "      <td>[1855]</td>\n",
              "      <td>[1855, 16497, 14688, 10355, 14688, 16855, 4214...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>[18166, 4073, 10410, 411]</td>\n",
              "      <td>[16726, 4073, 10410]</td>\n",
              "      <td>[16726, 4073, 10410, 18166, 4073, 10410, 411]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "      <td>[3080, 5695, 1934, 14842, 2417]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "      <td>[10355, 12242]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ... Assignment group_GRP_9\n",
              "0                 login issue  ...                      0\n",
              "1                     outlook  ...                      0\n",
              "2                cant log vpn  ...                      0\n",
              "3  unable access hr tool page  ...                      0\n",
              "4                 skype error  ...                      0\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmgntD2xiTzE"
      },
      "source": [
        "**Seperating features and target:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnNULDTuNwa-",
        "outputId": "128594b4-3dee-43b0-eb27-92da3e021afb"
      },
      "source": [
        "ynames = list(df.iloc[:,5:].columns)\r\n",
        "y = df.iloc[:,5:].values\r\n",
        "x = df[\"combined_tokens\"]\r\n",
        "\r\n",
        "print('y (target) in a one-hot binarizer form:',y.shape)\r\n",
        "print('features:',x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y (target) in a one-hot binarizer form: (8040, 74)\n",
            "features: (8040,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qnps1gjivQi"
      },
      "source": [
        "For every record we have 1 at the group it belongs to otherwise 0\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DJmcAYrVOPV",
        "outputId": "adfcc058-2ac8-4ec1-e118-3e730f20d513"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i95etcCV8BW"
      },
      "source": [
        "**Should we use binary_crossentropy or categorical_crossentropy?**<br>\r\n",
        "If we have multi-label classification(when a datapoint belongs to multiple classes) we would use binary_crossentropy, but if we have a multi-class classification(when a datapoint belongs to a single classe) we would use a categorical_crossentropy.<br><br>\r\n",
        "So for every record we have 1 at the group it belongs to... so if we sum across axis=1 and find the max, it should be 1; which means that we have all 0's except one 1(hot) at the group(class) that particular record belongs to. In other words each datapoint just belongs to 1 class. Hence this is a multi-class classification and thus we will use categorical_crossentropy\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIxffexCPxYP",
        "outputId": "9e436685-4ad3-4798-b7d9-f1448298dc88"
      },
      "source": [
        "np.sum(y,axis=1).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Y09tPfXbu7"
      },
      "source": [
        "**Transforming combined_tokens into sequences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hshOt3oyM4hX"
      },
      "source": [
        "x_seq = [seq for seq in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "G2XBAfSVM4j5",
        "outputId": "4d1a78a7-b88d-4d62-bc85-e6addef00ea2"
      },
      "source": [
        "size_of_sequences = [len(i) for i in x]\r\n",
        "\r\n",
        "percentile90 = round(np.percentile(a=size_of_sequences, q=90),2)\r\n",
        "percentile95 = round(np.percentile(a=size_of_sequences, q=95),2)\r\n",
        "mean_size = round(np.mean(size_of_sequences),2) \r\n",
        "max_size = round(np.max(size_of_sequences),2)\r\n",
        "\r\n",
        "print(\" Max no. of tokens in short description (sequence): \",max_size)\r\n",
        "print(\" Avg. no. of tokens in short description (sequence): \",mean_size)\r\n",
        "print(\" 90% of the sequences are <=\",percentile90)\r\n",
        "print(\" 95% of the sequences are <=\",percentile95)\r\n",
        "distribution_plot(size_of_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Max no. of tokens in short description (sequence):  1820\n",
            " Avg. no. of tokens in short description (sequence):  25.32\n",
            " 90% of the sequences are <= 46.0\n",
            " 95% of the sequences are <= 76.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm0BFMCTXjfv"
      },
      "source": [
        "**95% of the sequence is 76.05 or below 76.05 whilst 90% of the sequences are 46 and below 46. Hence we will pad the sequence to 76**<br>\r\n",
        "**This means that sequnces greater than 76 will be trimmed down to 76 and sequences less than 76 will be padded to 76, thereby making all the sequences of the same size**<br>\r\n",
        "**Since 95% of the sequences in the dataset is <=76, hence it seems to be the apt value for padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o8ZTYlUb-sh",
        "outputId": "f8fce17f-857f-4a2a-9005-4a3e0b69ed83"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeEhnyFcYF_5"
      },
      "source": [
        "**Size of the vocabulary is 19235 i.e words are numbered from 0 - 19234**<br>\r\n",
        "Like we said that the sequences that are less than 76 will be padded to be 76, therefore the padding will be done with the number '19234' i.e all padded words will be 19234 and 19234 encodes the word 'DUMMYWORD'. Hence the padding word will be 'DUMMYWORD'<br><br>\r\n",
        "**Also we will do pre-padding.** This is because LSTMs are temporal i.e it has timestamps. Hence words coming at the later timestamps are retained more in the 'memory' as compared to the words at the beginning of the sequence. Hence we want dummy words in the beginning of the sequence instead at the end\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K5kPwJ8tJ4nE",
        "outputId": "ad147106-f647-42ce-c252-d768b68959de"
      },
      "source": [
        "# 19234 encodes 'DUMMYWORD'\r\n",
        "id2vocab[19234]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DUMMYWORD'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfU9BhLAa87P"
      },
      "source": [
        "Pre-Padding with value len(vocabulary)-1 i.e 19234 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4QbPzikblPh",
        "outputId": "4190ae67-e27a-4961-cb18-f4f97be1126c"
      },
      "source": [
        "x_pad = pad_sequences(maxlen=76, sequences=x_seq, padding=\"pre\", value=len(vocabulary)-1)\r\n",
        "\r\n",
        "print(\"shape of x before padding\",np.array(x_seq).shape)\r\n",
        "print(\"shape of x after padding\",x_pad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x before padding (8040,)\n",
            "shape of x after padding (8040, 76)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd79VYsobM64"
      },
      "source": [
        "**Now we can make a 80:20 train test split:**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-pu9F6UiCWB",
        "outputId": "f8bbff08-fac0-4759-ea6f-f4ab342748fd"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_pad, y, test_size=0.20, random_state=777, stratify=y)\r\n",
        "\r\n",
        "print(\"train set\",x_train.shape)\r\n",
        "print(\"train labels\",y_train.shape,\"\\n\\n\")\r\n",
        "print(\"test set\",x_test.shape)\r\n",
        "print(\"test labels\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set (6432, 76)\n",
            "train labels (6432, 74) \n",
            "\n",
            "\n",
            "test set (1608, 76)\n",
            "test labels (1608, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaOV_4YtbSoi"
      },
      "source": [
        "**Creating glove embedding for the vocabulary:**<br>\r\n",
        "We will try both **pre-trained glove embeddings** and **tensorflow default embedding** that tensorflow trains during the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcpOZtIUNCz4"
      },
      "source": [
        "EMBEDDING_FILE = 'glove.6B.200d.txt'\r\n",
        "\r\n",
        "embeddings = {}\r\n",
        "for o in open(\"/content/drive/My Drive/capstone/\"+EMBEDDING_FILE):\r\n",
        "    word = o.split(\" \")[0]\r\n",
        "    embd = o.split(\" \")[1:]\r\n",
        "    embd = np.asarray(embd, dtype='float32')\r\n",
        "    embeddings[word] = embd\r\n",
        "\r\n",
        "# create a weight matrix for words in vocabulary\r\n",
        "embedding_matrix = np.zeros((len(vocabulary), 200))\r\n",
        "\r\n",
        "for word, i in vocab2id.items():\r\n",
        "\tembedding_vector = embeddings.get(word)\r\n",
        "\tif embedding_vector is not None:\r\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObuTCzPTcRUT"
      },
      "source": [
        "**All 19235 words have been replaced with corresponding 200 long glove vector:**<br> We can now use it as the weights in the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QRHQh9Ud8Oo",
        "outputId": "80421be7-00f8-47db-ac6d-ab1cc9195b3c"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19235, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIyUcnVzm0t0"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import pandas as pd\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input, GlobalMaxPool1D\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\r\n",
        "\r\n",
        "def train_model(model,xtr,ytr,xte,yte,ep,optm=\"adam\",bs=32,learn_rate=0.001,ver_bose=True,earlystop_nd_reducelronplateau=False,earlystop_params=None,reducelr_params=None):\r\n",
        "  if(optm==\"rmsprop\"):\r\n",
        "    opt = optimizers.RMSprop(learning_rate=learn_rate)\r\n",
        "  elif(optm==\"adam\"):\r\n",
        "    opt = optimizers.Adam(learning_rate = learn_rate)\r\n",
        "\r\n",
        "  model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "  if(ver_bose!=True):\r\n",
        "    model.fit(xtr, ytr, epochs=ep, batch_size=bs, validation_data=None, verbose=0)\r\n",
        "    print(\"model has been fitted.. evaluating on train and test set\")\r\n",
        "    score_train = model.evaluate(xtr, ytr, batch_size=bs, verbose=0)\r\n",
        "    score_test = model.evaluate(xte, yte, batch_size=bs, verbose=0)\r\n",
        "    return [model,score_train,score_test]\r\n",
        "  else:\r\n",
        "    if(earlystop_nd_reducelronplateau==True):\r\n",
        "      stop = EarlyStopping(monitor=earlystop_params['monitor'], min_delta=earlystop_params['min_delta'], patience=earlystop_params['patience'], verbose=earlystop_params['verbose'], mode=earlystop_params['mode'], restore_best_weights=earlystop_params['restore_best_weights'])\r\n",
        "      change_lr = ReduceLROnPlateau(monitor=r_lr_params['monitor'], factor=r_lr_params['factor'], patience=r_lr_params['patience'], verbose=r_lr_params['verbose'], mode=r_lr_params['mode'], min_delta=r_lr_params['min_delta'], min_lr=r_lr_params['min_lr'])\r\n",
        "      model.fit(xtr, ytr, batch_size=bs, epochs=ep, validation_data=(xte,yte), callbacks=[stop,change_lr], verbose=1)\r\n",
        "      return model\r\n",
        "    else:\r\n",
        "      model.fit(xtr, ytr, batch_size=bs, epochs=ep, validation_data=(xte,yte), verbose=1)\r\n",
        "      return model\r\n",
        "\r\n",
        "\r\n",
        "def show_training(history, filename=None, saveit=False):\r\n",
        "  hist_df = pd.DataFrame(history)\r\n",
        "\r\n",
        "  if(saveit==True):\r\n",
        "    if(filename==None):\r\n",
        "      return \"Please enter a valid filename\"\r\n",
        "    else:\r\n",
        "      hist_df.to_csv('/content/drive/My Drive/capstone/'+filename+'.csv',index=False)\r\n",
        "      print(\"Training history saved!\")\r\n",
        "\r\n",
        "  loss = hist_df['loss']\r\n",
        "  acc = hist_df['accuracy']\r\n",
        "  val_loss = hist_df['val_loss']\r\n",
        "  val_acc = hist_df['val_accuracy']\r\n",
        "  epoch = hist_df.shape[0]\r\n",
        "\r\n",
        "  figure, axes = plt.subplots(nrows=2, ncols=1, figsize=(13, 7))\r\n",
        "\r\n",
        "  axes[0].plot(range(0,epoch), loss, label=\"train loss\")\r\n",
        "  axes[0].plot(range(0,epoch), val_loss, label=\"test loss\")\r\n",
        "  axes[0].set_title(\"Loss vs Epoch\")\r\n",
        "  axes[0].set_xlabel(\"Epochs\")\r\n",
        "  axes[0].set_ylabel(\"Loss\")\r\n",
        "  axes[0].legend()\r\n",
        "\r\n",
        "  axes[1].plot(range(0,epoch), acc, label=\"train acc\")\r\n",
        "  axes[1].plot(range(0,epoch), val_acc, label=\"test acc\")\r\n",
        "  axes[1].set_title(\"Accuracy vs Epoch\")\r\n",
        "  axes[1].set_xlabel(\"Epochs\")\r\n",
        "  axes[1].set_ylabel(\"Accuracy\")\r\n",
        "  axes[1].legend()\r\n",
        "\r\n",
        "  figure.show()\r\n",
        "  plt.tight_layout()\r\n",
        "\r\n",
        "  if('lr' in list(hist_df.columns)):\r\n",
        "    plt.figure(figsize=(7, 3))\r\n",
        "    plt.plot(range(0,epoch), hist_df[\"lr\"])\r\n",
        "    plt.title(\"ReduceLROnPlateau\")\r\n",
        "    plt.xlabel(\"Epochs\")\r\n",
        "    plt.ylabel(\"Learning Rate\")\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-_uhssT2ei"
      },
      "source": [
        "#  --------END---------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-vlJopXT2aj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHLpT4h6T2YN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hahtudb5T2TV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yueN3i7ZT2B3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKncQbCIT18V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIQQ78A3T15s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7pq3ChpT5qU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8AQzxoQT5sU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nYAJ0GqT5t2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oYDNNvT5wM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPo68cMT5yV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLUPQ70BT50e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkHVe7MLT53Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGgnoayyT54z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oseJF9CeT12u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fZQMa8jT10H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGiXNG5A0oOa",
        "outputId": "f515c99f-6b9f-42dd-a097-cc80de3c2983"
      },
      "source": [
        "input = Input(shape=(x_train.shape[1],),batch_size=None)\r\n",
        "model = Embedding(input_dim=len(vocabulary), output_dim=200, input_length=x_train.shape[1])(input)\r\n",
        "model = LSTM(units=100, return_sequences=False, recurrent_dropout=0.1)(model)\r\n",
        "model = Dropout(0.1)(model)\r\n",
        "out = Dense(y_train.shape[1], activation=\"softmax\")(model)\r\n",
        "model = Model(input, out)\r\n",
        "model.summary()\r\n",
        "print(\"####################################\\n\")\r\n",
        "\r\n",
        "model = train_model(model, x_train, y_train, x_test, y_test, ep=5, bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 76)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 76, 200)           3847000   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 74)                7474      \n",
            "=================================================================\n",
            "Total params: 3,974,874\n",
            "Trainable params: 3,974,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####################################\n",
            "\n",
            "Epoch 1/5\n",
            "402/402 [==============================] - 65s 162ms/step - loss: 2.4439 - accuracy: 0.4894 - val_loss: 2.0604 - val_accuracy: 0.5348\n",
            "Epoch 2/5\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 1.8121 - accuracy: 0.5745 - val_loss: 1.8230 - val_accuracy: 0.5852\n",
            "Epoch 3/5\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 1.3754 - accuracy: 0.6558 - val_loss: 1.6982 - val_accuracy: 0.5970\n",
            "Epoch 4/5\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 1.0069 - accuracy: 0.7512 - val_loss: 1.6907 - val_accuracy: 0.6206\n",
            "Epoch 5/5\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.7319 - accuracy: 0.8221 - val_loss: 1.6847 - val_accuracy: 0.6063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6RK2RX69-xw",
        "outputId": "f5373928-26f2-49b6-e305-b4d76fed608c"
      },
      "source": [
        "y_pred = model.predict(x_test)\r\n",
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1608, 74)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80YR9w0wHTtu",
        "outputId": "211716e4-8794-4e32-9af0-3fa89ae807cf"
      },
      "source": [
        "y_pred.max(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7600393 , 0.99840647, 0.99657744, ..., 0.7388821 , 0.96210766,\n",
              "       0.6019875 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtHOmfjfH3Bc",
        "outputId": "c97cee20-3022-4803-a1b7-5e8c7bbb3652"
      },
      "source": [
        "y_test.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([59,  0,  0, ..., 72, 12,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsBh95eaH3Jd"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\r\n",
        "def evaluation_metrics(ytrue, ypred_proba, multiclass, avg):\r\n",
        "  '''\r\n",
        "  Prints F1 Score, Accuracy and ROC-AUC score. Since we have multiclass classification you will need\r\n",
        "  to specify multiclass strategy for ROC-AUC and averaging strategy for F1 Score.\r\n",
        "  NOTE THAT: \r\n",
        "  - ROC-AUC only support macro averaging; while f1-score supports both macro and micro\r\n",
        "  - F1-score does not have multiclass parameter hence it does not take 'ovo' or 'ovr' into account. ROC-AUC supports multiclass\r\n",
        "  - Accuracy is independent of these two parameters. They are not applicable to accuracy\r\n",
        "\r\n",
        "  ytrue: true labels (array/list/series)\r\n",
        "  ypred_proba: predicted probabilities (array/list/series)\r\n",
        "  multiclass: multi-class strategy; enter 'ovr' for OneVsRest and 'ovo' for OneVsOne (string)\r\n",
        "  avg: averaging strategy; accepts 'micro', 'macro' and 'weighted' (string)\r\n",
        "  '''\r\n",
        "  if(avg==\"macro\"):\r\n",
        "      print(\"Accuracy:\",accuracy_score(ytrue, ypred_proba.argmax(axis=1)))\r\n",
        "      # print(\"ROC-AUC:\",roc_auc_score(y_true=ytrue, y_score=ypred_proba.max(axis=1), multi_class=multiclass, average=\"macro\"))\r\n",
        "      print(\"(\"+avg+\") F1 Score:\",f1_score(y_true=ytrue, y_pred=ypred_proba.argmax(axis=1), average=avg))\r\n",
        "  else:\r\n",
        "      print(\"(\"+avg+\") F1 Score:\",f1_score(y_true=ytrue, y_pred=ypred_proba.argmax(axis=1), average=avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di8AnrFjKBUn",
        "outputId": "78396fb2-4f44-40b3-9eef-32c342c5e8ff"
      },
      "source": [
        "evaluation_metrics(y_test.argmax(axis=1), y_pred, 'ovo','macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6063432835820896\n",
            "(macro) F1 Score: 0.33841643212728606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsk6tSukKBXm",
        "outputId": "5d4b7dcf-ae53-4863-acfc-7d48e3850bdb"
      },
      "source": [
        "evaluation_metrics(y_test.argmax(axis=1), y_pred, 'ovo','micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(micro) F1 Score: 0.6063432835820896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE1sqRCfKBZ9",
        "outputId": "279c38f8-7852-44dd-dba6-5169ca2b88c9"
      },
      "source": [
        "roc_auc_score(y_true=y_test, y_score=y_pred, multi_class=\"ovo\", average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9015660986548211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExDUGVuTQtBR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGA8Mh0JQtJC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZOL3601QtL0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TZquy3HevUF",
        "outputId": "2f84b5e9-1a17-4691-eaad-9baf03a7a06f"
      },
      "source": [
        "input = Input(shape=(x_train.shape[1],),batch_size=None)\r\n",
        "model = Embedding(input_dim=len(vocabulary), output_dim=embedding_matrix.shape[1], weights=[embedding_matrix], input_length=x_train.shape[1], trainable=True)(input)\r\n",
        "model = LSTM(units=100, return_sequences=False, recurrent_dropout=0.1)(model)\r\n",
        "model = Dropout(0.1)(model)\r\n",
        "out = Dense(y_train.shape[1], activation=\"softmax\")(model)\r\n",
        "model = Model(input, out)\r\n",
        "model.summary()\r\n",
        "print(\"####################################\\n\")\r\n",
        "\r\n",
        "train_model(model, x_train, y_train, x_test, y_test, 5, bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_69\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_37 (InputLayer)        [(None, 76)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_36 (Embedding)     (None, 76, 200)           3847000   \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 74)                7474      \n",
            "=================================================================\n",
            "Total params: 3,974,874\n",
            "Trainable params: 3,974,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####################################\n",
            "\n",
            "Epoch 1/5\n",
            "402/402 [==============================] - 67s 166ms/step - loss: 2.2534 - accuracy: 0.5106 - val_loss: 1.8799 - val_accuracy: 0.5522\n",
            "Epoch 2/5\n",
            "402/402 [==============================] - 66s 165ms/step - loss: 1.6209 - accuracy: 0.6057 - val_loss: 1.5818 - val_accuracy: 0.6244\n",
            "Epoch 3/5\n",
            "402/402 [==============================] - 69s 171ms/step - loss: 1.2189 - accuracy: 0.6901 - val_loss: 1.4451 - val_accuracy: 0.6350\n",
            "Epoch 4/5\n",
            "402/402 [==============================] - 66s 164ms/step - loss: 0.9022 - accuracy: 0.7721 - val_loss: 1.4110 - val_accuracy: 0.6468\n",
            "Epoch 5/5\n",
            "402/402 [==============================] - 66s 164ms/step - loss: 0.6375 - accuracy: 0.8360 - val_loss: 1.3991 - val_accuracy: 0.6611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f88e4e6c7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    }
  ]
}